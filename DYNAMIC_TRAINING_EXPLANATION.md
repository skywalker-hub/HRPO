# åŠ¨æ€è®­ç»ƒ Thinking Projection çš„å®ç°è¯´æ˜

## ğŸ¯ æ ¸å¿ƒé—®é¢˜

åŸå§‹å®ç°ä¸­ï¼Œ`thinking_projection` åœ¨ GRPO è®­ç»ƒè¿‡ç¨‹ä¸­**æ— æ³•è¢«è®­ç»ƒ**ï¼Œå› ä¸ºï¼š

1. **ç”Ÿæˆé˜¶æ®µ**: thinking states æ˜¯åœ¨æ¨ç†æ¨¡å¼ä¸‹ç”Ÿæˆçš„ï¼ˆæ— æ¢¯åº¦ï¼‰
2. **è®­ç»ƒé˜¶æ®µ**: ä½¿ç”¨çš„æ˜¯ç”Ÿæˆé˜¶æ®µä¿å­˜çš„ frozen thinking states
3. **ç»“æœ**: æ¢¯åº¦æ— æ³•åå‘ä¼ æ’­åˆ° `thinking_projection`

## âœ… è§£å†³æ–¹æ¡ˆ

### æ ¸å¿ƒæ€è·¯

åœ¨è®­ç»ƒé˜¶æ®µ**åŠ¨æ€é‡è®¡ç®—** thinking statesï¼Œè€Œä¸æ˜¯ä½¿ç”¨ frozen çš„é¢„å­˜å€¼ï¼š

```
ç”Ÿæˆé˜¶æ®µï¼ˆæ— æ¢¯åº¦ï¼‰:
  Token â†’ Model â†’ Hidden States â†’ thinking_projection â†’ thinking_states
                                        â†“ (frozen, ä¿å­˜)
                                   å­˜å‚¨ç”¨äºå¥–åŠ±è®¡ç®—

è®­ç»ƒé˜¶æ®µï¼ˆæœ‰æ¢¯åº¦ï¼‰:
  Step 1: é‡æ–°å‰å‘è·å– Hidden States (no_grad)
  Step 2: Hidden States â†’ thinking_projection â†’ thinking_states_dynamic
                              â†“ (WITH GRADIENTS!)
          thinking_states_dynamic â†’ thinking_residual â†’ Fused Embedding
                                          â†“
                                    Model Forward
                                          â†“
                                       Loss
                                          â†“
                                    Backward()
                                          â†“
                              Gradients flow to thinking_projection!
```

---

## ğŸ“ ä¿®æ”¹å†…å®¹

### 1. ä¿®æ”¹ `unsloth/models/llama.py` (ç¬¬663-705è¡Œ)

æ·»åŠ äº†åŠ¨æ€é‡è®¡ç®—é€»è¾‘ï¼š

```python
def LlamaModel_fast_forward(..., **kwargs):
    ...
    thinking_mask = kwargs.get('thinking_mask')
    recompute_thinking_projection = kwargs.get('recompute_thinking_projection', False)
    thinking_hidden_states_cache = kwargs.get('thinking_hidden_states_cache', None)
    
    if thinking_mask is not None:
        if recompute_thinking_projection and self.training and thinking_hidden_states_cache is not None:
            # åŠ¨æ€è®­ç»ƒæ¨¡å¼ï¼š
            # ä»ç¼“å­˜çš„ hidden states é‡æ–°è®¡ç®— thinking states
            hidden_for_thinking = thinking_hidden_states_cache[thinking_mask]
            
            # å…³é”®ï¼šé€šè¿‡ thinking_projection åˆ›å»ºè®¡ç®—å›¾
            thinking_embeds_dynamic = self.thinking_projection(hidden_for_thinking)
            thinking_embeds_dynamic = thinking_embeds_dynamic / (
                torch.norm(thinking_embeds_dynamic, dim=-1, keepdim=True) + 1e-8
            )
            
            # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„ thinking states
            new_inputs_embeds[thinking_mask] = self.thinking_residual(
                inputs_embeds[thinking_mask], 
                thinking_embeds_dynamic,  # å¸¦æ¢¯åº¦ï¼
            )[0].to(inputs_embeds.dtype)
        else:
            # æ¨ç†æ¨¡å¼ï¼šä½¿ç”¨ frozen thinking_embeds
            new_inputs_embeds[thinking_mask] = self.thinking_residual(
                inputs_embeds[thinking_mask], 
                thinking_embeds[thinking_mask],  # frozen
            )[0].to(inputs_embeds.dtype)
```

**å…³é”®ç‚¹**:
- `thinking_hidden_states_cache`: ç¼“å­˜çš„ hidden states
- `thinking_embeds_dynamic`: é€šè¿‡ `thinking_projection` åŠ¨æ€è®¡ç®—ï¼ˆå¸¦æ¢¯åº¦ï¼‰
- åªåœ¨ `training=True` ä¸” `recompute_thinking_projection=True` æ—¶å¯ç”¨

---

### 2. ä¿®æ”¹ `unsloth/models/rl_replacements.py` (ç¬¬408-439è¡Œ)

ä¿®æ”¹ GRPO æŸå¤±è®¡ç®—ï¼Œæ·»åŠ ä¸¤æ­¥å‰å‘ä¼ æ’­ï¼š

```python
def grpo_accumulated_loss(...):
    ...
    if thinking_embeds is not None and thinking_mask is not None:
        # STEP 1: è·å– hidden statesï¼ˆæ— æ¢¯åº¦ï¼‰
        with torch.no_grad():
            temp_outputs = trainer.model(
                input_ids = input_ids,
                output_hidden_states = True,
                logits_to_keep = logits_to_keep + 1
            )
            thinking_hidden_states_cache = temp_outputs.hidden_states[-1]
            del temp_outputs
        
        # STEP 2: ä½¿ç”¨ç¼“å­˜çš„ hidden states è¿›è¡Œè®­ç»ƒï¼ˆæœ‰æ¢¯åº¦ï¼‰
        new_hidden_states = trainer.model(
            input_ids = input_ids,
            inputs_embeds = thinking_embeds,
            thinking_mask = thinking_mask,
            logits_to_keep = logits_to_keep + 1,
            recompute_thinking_projection = True,  # å¯ç”¨åŠ¨æ€é‡è®¡ç®—
            thinking_hidden_states_cache = thinking_hidden_states_cache  # ä¼ å…¥ cache
        ).logits
```

**ä¸ºä»€ä¹ˆéœ€è¦ä¸¤æ­¥**:
1. **ç¬¬ä¸€æ­¥ï¼ˆæ— æ¢¯åº¦ï¼‰**: è·å–"å¹²å‡€"çš„ hidden statesï¼Œä¸å— thinking fusion å½±å“
2. **ç¬¬äºŒæ­¥ï¼ˆæœ‰æ¢¯åº¦ï¼‰**: ä½¿ç”¨ç¼“å­˜çš„ hidden states åŠ¨æ€è®¡ç®— thinking statesï¼Œå®Œæ•´çš„æ¢¯åº¦æµ

---

## ğŸ”„ å®Œæ•´çš„æ¢¯åº¦æµ

```
è®­ç»ƒæ—¶çš„è®¡ç®—å›¾:

input_ids
   â†“
Model Embedding
   â†“
[Position where thinking_mask=True]
   â†“
hidden_states (from cache, no_grad)
   â†“
thinking_projection (trainable!)  â† å…³é”®ï¼šè¿™é‡Œåˆ›å»ºæ¢¯åº¦è®¡ç®—å›¾
   â†“
thinking_embeds_dynamic (with grad)
   â†“
thinking_residual (gate_r, gate_i, Lambda trainable)
   â†“
fused_embedding
   â†“
ç»§ç»­ Model Forward
   â†“
Logits
   â†“
GRPO Loss = f(logits, old_logits, advantages)
   â†“
loss.backward()
   â†“
æ¢¯åº¦åå‘ä¼ æ’­åˆ°:
  âœ… thinking_projection  â† ç°åœ¨å¯ä»¥è®­ç»ƒäº†ï¼
  âœ… thinking_residual_gate_r
  âœ… thinking_residual_gate_i  
  âœ… thinking_residual_Lambda
  âœ… LoRA adapters
```

---

## ğŸ“Š æ€§èƒ½å½±å“

### é¢å¤–è®¡ç®—å¼€é”€

- **ä¸€æ¬¡é¢å¤–çš„å‰å‘ä¼ æ’­**ï¼ˆSTEP 1ï¼‰æ¥è·å– hidden states
  - ä½†ä½¿ç”¨ `torch.no_grad()`ï¼Œä¸è®¡ç®—æ¢¯åº¦
  - çº¦å¢åŠ  30-40% çš„å‰å‘è®¡ç®—æ—¶é—´

- **ä¸€æ¬¡ thinking_projection è°ƒç”¨**ï¼ˆSTEP 2ï¼‰
  - çº¿æ€§å˜æ¢: `O(dÂ²)` å…¶ä¸­ d = hidden_size
  - å¯¹äº d=2048: çº¦ 4M FLOPs per token
  - ç›¸å¯¹äºæ•´ä¸ªæ¨¡å‹å¾ˆå°

### å†…å­˜å¼€é”€

- **thinking_hidden_states_cache**: `(batch_size, seq_len, hidden_size)`
  - å¯¹äº batch_size=8, seq_len=1024, hidden_size=2048:
  - çº¦ 128MB (fp16/bf16)
  - è®­ç»ƒç»“æŸåç«‹å³é‡Šæ”¾

### è®­ç»ƒé€Ÿåº¦ä¼°è®¡

- é¢„è®¡è®­ç»ƒé€Ÿåº¦é™ä½çº¦ **20-30%**
- ä½†æ¢æ¥äº† `thinking_projection` çš„å¯è®­ç»ƒæ€§
- å€¼å¾—trade-offï¼

---

## âœ¨ ä¼˜åŠ¿

1. **çœŸæ­£çš„ç«¯åˆ°ç«¯è®­ç»ƒ**: thinking_projection å¯ä»¥æ ¹æ® GRPO æŸå¤±è¢«ä¼˜åŒ–
2. **ä»»åŠ¡è‡ªé€‚åº”**: å¯ä»¥å­¦ä¹ ç‰¹å®šä»»åŠ¡çš„æœ€ä¼˜æŠ•å½±æ–¹å‘
3. **ä¿æŒå…¼å®¹æ€§**: æ¨ç†æ—¶ä»ä½¿ç”¨åŸå§‹è·¯å¾„ï¼ˆæ— é¢å¤–å¼€é”€ï¼‰
4. **å¹³æ»‘è®­ç»ƒ**: å°åˆå§‹åŒ–ï¼ˆstd=0.001ï¼‰ç¡®ä¿è®­ç»ƒç¨³å®šæ€§

---

## ğŸ§ª éªŒè¯æ–¹æ³•

è®­ç»ƒæ—¶ç›‘æ§ thinking_projection çš„å˜åŒ–ï¼š

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ ï¼š
import torch

# è®­ç»ƒå‰
initial_proj = model.model.model.thinking_projection.weight.clone()

# æ¯éš” N æ­¥
if global_step % 100 == 0:
    current_proj = model.model.model.thinking_projection.weight
    weight_change = (current_proj - initial_proj).abs().mean().item()
    
    if model.model.model.thinking_projection.weight.grad is not None:
        grad_norm = model.model.model.thinking_projection.weight.grad.norm().item()
        print(f"Step {global_step}:")
        print(f"  Weight change: {weight_change:.6f}")
        print(f"  Gradient norm: {grad_norm:.6f}")
    else:
        print(f"Step {global_step}: No gradient!")
```

**é¢„æœŸç»“æœ**:
- Weight change åº”è¯¥ä» 0 é€æ¸å¢å¤§
- Gradient norm åº”è¯¥éé›¶ä¸”éšè®­ç»ƒå˜åŒ–

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **å†…å­˜ä½¿ç”¨**: ä¼šç¼“å­˜ä¸€ä»½ hidden statesï¼Œæ³¨æ„æ˜¾å­˜
2. **è®­ç»ƒé€Ÿåº¦**: ä¼šæœ‰ 20-30% çš„é€Ÿåº¦ä¸‹é™
3. **æ•°å€¼ç¨³å®šæ€§**: å½’ä¸€åŒ–å¾ˆé‡è¦ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸
4. **åˆå§‹åŒ–**: ä¿æŒ std=0.001 çš„å°åˆå§‹åŒ–å¾ˆå…³é”®

---

## ğŸ¯ ä½¿ç”¨å»ºè®®

### è®­ç»ƒç­–ç•¥

**é€‰é¡¹ 1: å…¨ç¨‹å¯ç”¨åŠ¨æ€è®­ç»ƒ**
```bash
python hrpo_gsm8k.py \
  --model_name Qwen/Qwen2.5-1.5B-Instruct \
  --lr_thinking_projection 1e-4
```
- ä¼˜ç‚¹ï¼šthinking_projection ä»å¤´å­¦ä¹ 
- ç¼ºç‚¹ï¼šè®­ç»ƒæ…¢ 20-30%

**é€‰é¡¹ 2: ä¸¤é˜¶æ®µè®­ç»ƒ**
```bash
# é˜¶æ®µ1: å†»ç»“ thinking_projectionï¼ˆåŸå§‹è¡Œä¸ºï¼‰
python hrpo_gsm8k.py --lr_thinking_projection 0

# é˜¶æ®µ2: è§£å†»å¹¶ç²¾è°ƒ
python hrpo_gsm8k.py \
  --resume_from_checkpoint checkpoint-xxx \
  --lr_thinking_projection 5e-5
```
- ä¼˜ç‚¹ï¼šç¬¬ä¸€é˜¶æ®µè®­ç»ƒå¿«
- ç¼ºç‚¹ï¼šéœ€è¦ä¸¤æ¬¡è®­ç»ƒ

### å­¦ä¹ ç‡å»ºè®®

- `thinking_projection`: 1e-4 (é»˜è®¤) æˆ– 5e-5 (ä¿å®ˆ)
- ç›¸å¯¹äºä¸» LR (5e-6) é«˜çº¦ 20 å€
- å› ä¸º thinking_projection åˆå§‹åŒ–æ¥è¿‘é›¶ï¼Œéœ€è¦è¾ƒå¤§ LR æ¥æ‰“ç ´å¯¹ç§°æ€§

---

**ä¿®æ”¹å®Œæˆæ—¶é—´**: 2025-10-17  
**çŠ¶æ€**: âœ… å·²å®ç°ï¼Œå¾…æµ‹è¯•

